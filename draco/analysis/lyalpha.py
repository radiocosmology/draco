import numpy as np

from caput import config, pipeline, mpiarray
from cora.util import units, coord

from ..core import task, containers
from ..analysis import transform
from ..util import tools


# Wavelengths of lyman-alpha and 21cm transitions
LAM_LYA = 121.567e-9
LAM_21 = 0.21106114054160


class CombineLymanAB(task.SingleTask):
    """Combine Lyman-alpha spectra from the Lyman-alpha and Lyman-beta spectral
    regions onto a common grid.
    """

    def process(self, alpha, beta):
        """Combine two spectra generated by :class:`..core.io.LoadFITSDelta`.

        Parameters
        ----------
        alpha : :class:`..core.containers.FormedBeam`
            Spectra for the Lyman-alpha region.
        beta : :class:`..core.containers.FormedBeam`
            Spectra for the Lyman-beta region.

        Returns
        -------
        deltas : :class:`..core.containers.FormedBeam`
            Combined spectra.
        """

        self.log.debug(
            f"Received Lyman-alpha region tagged {alpha.attrs['tag']}, and "
            f"Lyman-beta region tagged {beta.attrs['tag']}."
        )

        # create a new frequency axis
        # spectral pixels are evenly spaced in log wavelength
        llam_alpha = np.log10(units.c / alpha.freq[:] * 1e4)
        llam_beta = np.log10(units.c / beta.freq[:] * 1e4)
        llam_min = llam_beta.min()
        llam_max = llam_alpha.max()
        dllam = np.min(np.abs(np.diff(llam_alpha)))
        if dllam != np.min(np.abs(np.diff(llam_beta))):
            raise pipeline.PipelineRuntimeError(
                "Lyman-alpha and -beta arrays don't share a common grid."
            )
        nlam = int(np.round((llam_max - llam_min) / dllam)) + 1
        lam = np.power(10, llam_min + np.arange(nlam) * dllam)
        freq = units.c / lam * 1e4

        # check datasets are not distributed
        if alpha["beam"].distributed:
            alpha.dataset_distributed_to_common("beam")
            alpha.dataset_distributed_to_common("weight")
        if beta["beam"].distributed:
            beta.dataset_distributed_to_common("beam")
            beta.dataset_distributed_to_common("weight")

        # create an array for combined deltas
        delta_comb = np.zeros(
            alpha["beam"].shape[:-1] + (len(freq),), dtype=alpha["beam"].dtype
        )
        weight_comb = np.zeros(
            alpha["weight"].shape[:-1] + (len(freq),), dtype=alpha["weight"].dtype
        )

        # fill in lyman-alpha region
        offset = np.argmin(np.abs(freq - alpha.freq[0]))
        delta_comb[..., offset:] = alpha["beam"][:]
        weight_comb[..., offset:] = alpha["weight"][:]

        # iterate over beta objects and copy into combined array
        for bi, oid in enumerate(beta.id):
            # find index into combined array
            ai = np.where(alpha.id[:] == oid)[0]
            if len(ai) == 0:
                self.log.warn(
                    f"Could not find object ID {oid} in Lyman-alpha region dataset."
                )
                continue
            elif len(ai) > 1:
                self.log.warn(
                    f"Found more than one object with ID {oid} in Lyman-alpha region dataset."
                )
            ai = ai[0]
            # lower bound is the same for beta and combined array
            nz_ind = np.where(beta["weight"][bi, 0] != 0)[0]

            # copy lyman-beta region into combined array
            # N.B. by construction there should be no overlap with alpha region
            delta_comb[ai, :, nz_ind] = beta["beam"][bi, :, nz_ind]
            weight_comb[ai, :, nz_ind] = beta["weight"][bi, :, nz_ind]

        # create new container for combined datasets
        deltas = containers.FormedBeam(
            axes_from=alpha, attrs_from=alpha, freq=freq, comm=self.comm
        )

        # copy into common dataset
        deltas.dataset_distributed_to_common("beam")
        deltas.dataset_distributed_to_common("weight")
        deltas["beam"][:] = delta_comb
        deltas["weight"][:] = weight_comb

        # also copy auxiliary datasets
        deltas["redshift"][:] = alpha["redshift"][:]
        deltas["position"][:] = alpha["position"][:]

        # distribute before returning
        deltas.dataset_common_to_distributed("beam")
        deltas.dataset_common_to_distributed("weight")

        return deltas


class TruncateRedshift(task.SingleTask):
    """Truncate the Lyman-alpha spectra to a given range in redshift.

    Attributes
    ----------
    zmin : float
        The lower bound in redshift.
    zmax : float
        The upper bound in redshift.
    rest_wavelength : float
        Rest wavelength of the Lyman-alpha transition.
    """

    zmax = config.Property(proptype=float, default=np.inf)
    zmin = config.Property(proptype=float, default=0.0)
    rest_wavelength = config.Property(proptype=float, default=1215.67)  # Angstrom

    def process(self, deltas):
        """Truncate the frequency axis to given redshift bounds.

        Parameters
        ----------
        deltas : :class:`..core.containers.FormedBeam`
            Lyman-alpha spectra.
        """

        # convert redshift to frequency
        fmin = units.c / (self.zmax + 1) / self.rest_wavelength * 1e4
        fmax = units.c / (self.zmin + 1) / self.rest_wavelength * 1e4

        # construct frequency slice
        max_ind = np.argmin(np.abs(deltas.freq[:] - fmax))
        min_ind = np.argmin(np.abs(deltas.freq[:] - fmin))
        fslice = (
            slice(max_ind, min_ind + 1)
            if max_ind < min_ind
            else slice(min_ind, max_ind + 1)
        )

        if fslice.start == 0 and fslice.stop == len(deltas.freq):
            self.log.warn("Redshift bounds overlap the entire band. Doing nothing.")
            return deltas
        elif fslice.start == fslice.stop:
            self.log.warn("Redshift bounds have no overlap with data.")
            return None

        # define a new frequency axis
        freq = deltas.freq[fslice]

        # create a new container
        out = containers.FormedBeam(
            axes_from=deltas, attrs_from=deltas, freq=freq, comm=self.comm
        )

        # fill with truncated frequency axis
        deltas.redistribute("object_id")
        out.redistribute("object_id")
        out["beam"][:] = deltas["beam"][:, :, fslice]
        out["weight"][:] = deltas["weight"][:, :, fslice]
        out["position"][:] = deltas["position"][:]
        out["redshift"][:] = deltas["redshift"][:]

        return out


class SpectralRegridder(transform.Regridder):

    zero_weight_thresh = config.Property(proptype=float, default=3.0)

    def process(self, formed):

        # convert observed to equivalent CHIME frequency
        lya_freq = formed.freq[:] * LAM_LYA / LAM_21

        # redistribute
        formed.redistribute("object_id")

        # move frequency axis last
        spec = formed.beam[:].view(np.ndarray)
        weight = formed.weight[:].view(np.ndarray)

        # perform regridding
        new_grid, sts, ni = self._regrid(spec, weight, lya_freq)

        # create new container
        out = containers.FormedBeam(axes_from=formed, attrs_from=formed, freq=new_grid)
        out.redistribute("object_id")

        # mask outside of overlap region
        mask = (out.freq[:] <= lya_freq.max()) & (out.freq[:] >= lya_freq.min())
        ni *= mask

        # mask weights below a threshold
        with np.errstate(divide="ignore", invalid="ignore"):
            mask = (ni > self.snr_cov * self.zero_weight_thresh) * mask

        # copy over datasets
        out.beam[:] = sts * mask
        out.weight[:] = ni * mask
        out["position"][:] = formed["position"][:]
        out["redshift"][:] = formed["redshift"][:]

        return out


class SelectField(task.SingleTask):
    """Select objects in the catalog that are in either the NGC or SGC field.

    Attributes
    ----------
    field : str
        Name of the field. One of "NGC" or "SGC".
    """

    field = config.enum(["NGC", "SGC"], default="NGC")

    def process(self, formed):
        """Select objects that are in the chosen field.

        Parameters
        ----------
        formed : :class:`..core.containers.FormedBeam`
        """

        # redistribute over frequency
        formed.redistribute("freq")

        # select lines of sight in field
        if self.comm.rank == 0:
            ra, dec = formed["position"]["ra"], formed["position"]["dec"]

            # convert to spherical coords
            phi, theta = np.radians(ra), 0.5 * np.pi - np.radians(dec)

            # rotate to galactic
            gal = _cel2gal(np.array((theta, phi)).T)

            if self.field == "NGC":
                sel = gal[:, 0] <= 0.5 * np.pi
            else:
                sel = gal[:, 0] > 0.5 * np.pi
        else:
            sel = None

        # broadcast selection to other ranks
        sel = self.comm.bcast(sel, root=0)

        # create a new container
        out = containers.empty_like(formed, object_id=formed.id[sel])
        out.redistribute("freq")

        # copy over data
        out.beam[:] = formed.beam[:][sel]
        out.weight[:] = formed.weight[:][sel]
        out["position"][:] = formed["position"][:][sel]
        out["redshift"][:] = formed["redshift"][:][sel]

        return out


class XCorrBase(task.SingleTask):
    """Base task for performing cross-correlation between beamformed line of sight spectra."""

    def process(self, bfA, bfB):
        """Evaluate the cross-correlation function of two beamformed catalogues.

        Parameters
        ----------
        bfA : FormedBeam
            The first catalogue of beamformed data.
        bfB : FormedBeam
            The second catalogue of beamformed data.

        Returns
        -------
        corr : FormedBeam
            The cross-correlation function.
        """

        # redistribute so all frequencies are on every rank
        bfA.redistribute("object_id")
        bfB.redistribute("object_id")

        # we might have only only polarisation for one of the datasets
        if len(bfA.pol) > len(bfB.pol):
            axes = bfA
        else:
            axes = bfB

        # compute correlation function (returns on rank 0 only)
        df, corr = self._compute_corr(bfA, bfB)

        # create output container
        out = containers.FormedBeam(
            object_id=np.array([0]),
            freq=df,
            axes_from=axes,
            attrs_from=bfA,
            comm=axes.comm,
        )
        out.redistribute("object_id")
        out.weight[:].local_array[:] = 0.0

        # also copy remaining attrs
        for key, val in bfB.attrs.items():
            if key not in out.attrs:
                out.attrs[key] = val

        if corr is not None:
            out.beam[0] = corr

        return out


class XCorrFFT(XCorrBase):
    """Use the FFT to evaluate the cross power spectrum, then transform back to the correlation function."""

    def _compute_corr(self, bfA, bfB):

        # Fourier transform
        bfA_fft = np.fft.fft(bfA.beam[:] * (bfA.weight[:] != 0), axis=-1)
        bfB_fft = np.fft.fft(bfB.beam[:] * (bfB.weight[:] != 0), axis=-1)

        # estimate PS
        ps = np.sum(bfA_fft * bfB_fft.conj(), axis=0)
        ps = mpiarray.MPIArray.wrap(
            ps[np.newaxis, ...], axis=0, comm=self.comm
        ).gather()

        # transform back to correlation function
        # first, still need to sum over all ranks
        if self.comm.rank == 0:
            ps = np.sum(ps, axis=0)
            corr = np.fft.ifft(ps, axis=-1)
        else:
            corr = None

        # calculate frequencey separation axis
        N = bfA.beam.shape[-1]
        df = (np.arange(N) - N // 2) * np.abs(bfA.freq[1] - bfA.freq[0])

        if self.comm.rank == 0:
            return df, np.fft.fftshift(corr.real, axes=1)
        else:
            return df, None


class XCorrDirect(XCorrBase):
    """Evaluate the cross-correlation function directly in 'real' space.

    Attributes
    ----------
    N : int (optional)
        The number of separation bins to compute the correlation function at,
        centered around zero. Uses `2 * n - 1` by default, where `n` is the length
        of the spectrum.

    """

    N = config.Property(proptype=int, default=0)

    def _compute_corr(self, bfA, bfB):

        npol = max(len(bfA.pol), len(bfB.pol))
        N = bfA.beam.shape[-1] * 2 - 1 if self.N == 0 else self.N

        # if one of the polarisation axes is length 1, expand it to match full axis
        if len(bfA.pol) == 1 and npol != 1:
            bA = np.tile(bfA.beam[:].local_array, (1, npol, 1))
            bB = bfB.beam[:].local_array
            wA = np.tile(bfA.weight[:].local_array, (1, npol, 1))
            wB = bfB.weight[:].local_array
        elif len(bfB.pol) == 1 and npol != 1:
            bA = bfA.beam[:].local_array
            bB = np.tile(bfB.beam[:].local_array, (1, npol, 1))
            wA = bfA.weight[:].local_array
            wB = np.tile(bfB.weight[:].local_array, (1, npol, 1))
        else:
            bA = bfA.beam[:].local_array
            bB = bfB.beam[:].local_array
            wA = bfA.weight[:].local_array
            wB = bfB.weight[:].local_array

        # evaluate the correlation function on the local array
        corr = np.zeros((npol, N))
        norm = np.zeros((npol, N))
        for i in range(npol):
            corr[i] = tools.corr_func(bA[:, i] * wA[:, i], bB[:, i] * wB[:, i], N)
            norm[i] = tools.corr_func(wA[:, i], wB[:, i], N)
        # second normalisation is to match FFT method given unit weights
        norm2 = np.sum((wA * wB) != 0, axis=(0, 2))

        # combine all ranks
        corr = mpiarray.MPIArray.wrap(corr[np.newaxis, ...], axis=0, comm=self.comm)
        corr = corr.gather()
        norm = mpiarray.MPIArray.wrap(norm[np.newaxis, ...], axis=0, comm=self.comm)
        norm = norm.gather()
        norm2 = mpiarray.MPIArray.wrap(norm2[np.newaxis, :], axis=0, comm=self.comm)
        norm2 = norm2.gather()
        if self.comm.rank == 0:
            corr = np.sum(corr, axis=0)
            norm = np.sum(norm, axis=0)
            corr *= tools.invert_no_zero(norm)
            corr *= np.sum(norm2, axis=0)[:, np.newaxis]

        # calculate frequencey separation axis
        df = (np.arange(N) - N // 2) * np.abs(bfA.freq[1] - bfA.freq[0])

        if self.comm.rank == 0:
            return df, np.fft.fftshift(corr, axes=1)
        else:
            return df, None


# Galactic coordinates rotation
z_rot = -(12 + 51.4 / 60.0) * 2 * np.pi / 24
y_rot = (90.0 - 27.13) * np.pi / 180
R = np.dot(
    np.array(
        [
            [np.cos(y_rot), 0, np.sin(-y_rot)],
            [0, 1.0, 0],
            [np.sin(y_rot), 0.0, np.cos(y_rot)],
        ]
    ),
    np.array(
        [
            [np.cos(z_rot), np.sin(-z_rot), 0],
            [np.sin(z_rot), np.cos(z_rot), 0],
            [0, 0, 1.0],
        ]
    ),
)


def _cel2gal(sph_coords):
    cart = coord.sph_to_cart(sph_coords)
    gcart = np.matmul(R, cart[..., np.newaxis])[..., 0]
    return coord.cart_to_sph(gcart)[:, 1:]
