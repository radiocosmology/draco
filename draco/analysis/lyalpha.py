import numpy as np

from caput import config, pipeline
from cora.util import units

from ..core import task, containers


class CombineLymanAB(task.SingleTask):
    """Combine Lyman-alpha spectra from the Lyman-alpha and Lyman-beta spectral
    regions onto a common grid.
    """

    def process(self, alpha, beta):
        """Combine two spectra generated by :class:`..core.io.LoadFITSDelta`.

        Parameters
        ----------
        alpha : :class:`..core.containers.FormedBeam`
            Spectra for the Lyman-alpha region.
        beta : :class:`..core.containers.FormedBeam`
            Spectra for the Lyman-beta region.

        Returns
        -------
        deltas : :class:`..core.containers.FormedBeam`
            Combined spectra.
        """

        self.log.debug(
            f"Received Lyman-alpha region tagged {alpha.attrs['tag']}, and "
            f"Lyman-beta region tagged {beta.attrs['tag']}."
        )

        # create a new frequency axis
        # spectral pixels are evenly spaced in log wavelength
        llam_alpha = np.log10(units.c / alpha.freq[:] * 1e4)
        llam_beta = np.log10(units.c / beta.freq[:] * 1e4)
        llam_min = llam_beta.min()
        llam_max = llam_alpha.max()
        dllam = np.min(np.abs(np.diff(llam_alpha)))
        if dllam != np.min(np.abs(np.diff(llam_beta))):
            raise pipeline.PipelineRuntimeError(
                "Lyman-alpha and -beta arrays don't share a common grid."
            )
        nlam = int(np.round((llam_max - llam_min) / dllam)) + 1
        lam = np.power(10, llam_min + np.arange(nlam) * dllam)
        freq = units.c / lam * 1e4

        # check datasets are not distributed
        if alpha["beam"].distributed:
            alpha.dataset_distributed_to_common("beam")
            alpha.dataset_distributed_to_common("weight")
        if beta["beam"].distributed:
            beta.dataset_distributed_to_common("beam")
            beta.dataset_distributed_to_common("weight")

        # create an array for combined deltas
        delta_comb = np.zeros(
            alpha["beam"].shape[:-1] + (len(freq),), dtype=alpha["beam"].dtype
        )
        weight_comb = np.zeros(
            alpha["weight"].shape[:-1] + (len(freq),), dtype=alpha["weight"].dtype
        )

        # fill in lyman-alpha region
        offset = np.argmin(np.abs(freq - alpha.freq[0]))
        delta_comb[..., offset:] = alpha["beam"][:]
        weight_comb[..., offset:] = alpha["weight"][:]

        # iterate over beta objects and copy into combined array
        for bi, oid in enumerate(beta.id):
            # find index into combined array
            ai = np.where(alpha.id[:] == oid)[0]
            if len(ai) == 0:
                self.log.warn(
                    f"Could not find object ID {oid} in Lyman-alpha region dataset."
                )
                continue
            elif len(ai) > 1:
                self.log.warn(
                    f"Found more than one object with ID {oid} in Lyman-alpha region dataset."
                )
            ai = ai[0]
            # lower bound is the same for beta and combined array
            nz_ind = np.where(beta["weight"][bi, 0] != 0)[0]

            # copy lyman-beta region into combined array
            # N.B. by construction there should be no overlap with alpha region
            delta_comb[ai, :, nz_ind] = beta["beam"][bi, :, nz_ind]
            weight_comb[ai, :, nz_ind] = beta["weight"][bi, :, nz_ind]

        # create new container for combined datasets
        deltas = containers.FormedBeam(
            axes_from=alpha, attrs_from=alpha, freq=freq, comm=self.comm
        )

        # copy into common dataset
        deltas.dataset_distributed_to_common("beam")
        deltas.dataset_distributed_to_common("weight")
        deltas["beam"][:] = delta_comb
        deltas["weight"][:] = weight_comb

        # also copy auxiliary datasets
        deltas["redshift"][:] = alpha["redshift"][:]
        deltas["position"][:] = alpha["position"][:]

        # distribute before returning
        deltas.dataset_common_to_distributed("beam")
        deltas.dataset_common_to_distributed("weight")

        return deltas
